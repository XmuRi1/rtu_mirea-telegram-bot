import requests
from bs4 import BeautifulSoup
import json
import emoji

# –î–∞–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π covid_19_worker –ø–æ –†–æ—Å—Å–∏–∏ (rbk.com).


# –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —Å—Å—ã–ª–∫–∏ –æ—Ç –∫—É–¥–∞ BS –ø–æ–ª—É—á–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏:

URL = 'https://www.rbc.ru/story/5e2881539a794724ab627caa'
response = requests.get(URL)
soup = BeautifulSoup(response.content, 'html.parser')


# –ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏ —Å—Å—ã–ª–æ–∫ –Ω–∞ –Ω–æ–≤–æ—Å—Ç–∏:
def get_google_news():
    news_list = []
    headings = soup.find_all('a', {'class': 'item__link'}, limit=10)


    for header in headings:
        news = {'header': header.text.strip(),
                'href': (header.attrs.get("href"))}
        news_list.append(news)

    with open("covid_19_worker/BS_worker/news/rbk/news_google.json", "w",
              encoding="utf-8") as write_file:
        json.dump(news_list, write_file)

    message = show_google_news()
    return message


# –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å–æ –≤—Å–µ–º–∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏:
def show_google_news():
    message = emoji.emojize(
        "üìë") + " –°–∞–º—ã–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ —Å —Å–∞–π—Ç–∞ \"rbk.com\": \n \n"
    buff_counter = 1

    with open("covid_19_worker/BS_worker/news/rbk/news_google.json", "r",
              encoding="utf-8") as read_file:
        news = json.load(read_file)
        for new in news:
            header = new['header']
            href = new['href']
            message += '*' + str(
                buff_counter) + ".* [" + header + "]" + "(" + href + ").\n \n"
            buff_counter += 1
    return message
